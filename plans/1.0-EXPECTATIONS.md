curb 1.0: user expectations (solo devs + small teams)
This is the contract I’d expect curb to meet as a user, and it’s shaped heavily by adjacent tooling: Claude Code / Codex CLI (interactive coding agents), git-first agent editors (aider-style), and backlog runners (beads/Jira/Linear semantics).

1) What I expect curb to feel like day 1
“Time-to-first-value” (5 minutes)
I expect a single happy path that works without reading 10 pages.

Install
Initialize a tiny backlog (2-3 tasks)
Run one loop
See a clear artifact bundle: plan + diff + command outputs + status
If I can’t do this quickly, I’ll churn, because I can just use the underlying CLI directly.

“Progress equals diffs”
Similar to git-first tools, I expect curb’s core output to be reviewable changes, not chat transcripts.

Every task run should produce a patch or a committed branch (configurable)
Output should link to the exact files changed and the test results
“Safe by default”
Because curb is autonomous, I expect stricter defaults than interactive tools.

No pushing to remotes unless I opt in
No deleting files unless I opt in
No printing secrets (ever), with basic redaction
Sensible max-iteration / max-time / max-cost guardrails
2) What similar tools implicitly promise (and curb should make explicit)
From interactive coding CLIs (Claude Code / Codex CLI)
Implicit promise: the agent can operate a real repo, and I can stay oriented.

Curb should therefore:

Make repo context explicit at start (path, branch, dirty status)
Show a tight loop of: task -> plan -> edits -> verification -> summary
Fail fast with actionable diagnostics (missing deps, tool not installed, auth)
From git-first assistants (aider/SWE-agent-ish)
Implicit promise: even failure produces a useful artifact.

Curb should therefore:

Always emit an artifact bundle per task (see section 4)
Prefer patches/diffs over verbose logs
Support stop/resume without losing what happened
From backlog runners (beads-like)
Implicit promise: predictable scheduling and state transitions.

Curb should therefore define:

A task state machine (todo, in_progress, blocked, done, failed, skipped)
Dependency semantics (B never runs until A is done)
A stable, explainable scheduler (priority then creation order, etc.)
3) The 1.0 “user contract” (what I’d want written down)
A) Backlog + scheduling
Inputs supported: beads backend and prd.json backend
“Done” definition:
Minimum: task is marked done in the backend
Better: optional verification steps (per-task) that must pass
Scheduler guarantees:
Dependencies respected
Filters are consistent (priority, labels/epics)
Clear reasons when something is skipped/blocked
B) Git + change management
For solo devs and small teams, the workflow usually wants reviewable changes and minimal repo disruption.

Default mode: create diffs/patches but do not commit unless configured
Optional modes:
Commit per task
Branch per task
Branch per run
Never push by default
If auto-commit is enabled, commit messages should reference the task ID
C) Verification and feedback
Default verification should be cheap and predictable:
formatting (if configured)
unit tests (if configured)
typecheck/lint (if configured)
If verification fails, curb should:
capture the command output
mark task failed/blocked with a reason
optionally spawn a “fix verification” subtask or retry policy
D) Guardrails (autonomous loop safety)
maxIterations per task and/or per run
maxWallTime
budget/cost cap if possible
explicit allowlist/denylist for commands (at least a denylist for dangerous operations)
“plan-only” mode that never edits files
E) Observability (what I can see)
Streaming output is nice, but the durable artifacts matter more.
A structured run log (JSONL) that records:
timestamped events
task ID
selected model/tool
command executions
status transitions
4) Artifact bundle: what I expect per task
Per task ID, I want a predictable folder name, e.g.:

runs/<run-id>/tasks/<task-id>/
Containing:

task.json (normalized view: title, priority, deps, labels, acceptance checks)
plan.md (what it intends to do)
changes.patch (unified diff)
commands.jsonl or commands.txt (what it ran)
test.log (or verify.log)
summary.md (what changed, what’s left, final status)
Even if the loop fails, these files should exist.

5) Team workflow expectations (small teams)
Small teams mostly want: predictability, shareable artifacts, and easy review.

Runs should be shareable:
a single folder or tarball with artifacts
or a stable path committed to a shared store
Task runs should be easy to review in PRs:
optional “branch per task” mode
consistent commit messages
Concurrency should be explicit:
default single-worker
if multiple workers exist, define collision behavior
6) CLI UX expectations (what makes it feel polished)
curb init creates a minimal working config
curb run works with minimal flags
curb status shows what it did last and what’s next
curb explain <task> tells me why a task is blocked/skipped
curb artifacts <task> points me to the folder
If 1.0 doesn’t have all of these commands, the behavior should still map to these concepts.

7) What I’d personally prioritize for 1.0 (solo devs + small teams)
A boring, rock-solid happy path (install -> init -> run -> artifacts)
A crisp task state machine + dependency semantics
Artifact bundles that make failures useful
Guardrails that prevent runaway loops
Git workflow modes that match how people actually ship (patch, commit, branch)
8) Open questions worth deciding before you ship 1.0
What is the default “done” definition: backend-only, or backend + verification?
What is the default git mode: patch-only, or commit-per-task?
What is the default policy on retries?
What is the minimum guarantee for artifacts on crash/interrupt?
What’s the canonical config location and precedence (CLI flags vs config file vs env)?
